{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb144c61-4cb8-4b0e-a2c8-ad9be9663a4b",
   "metadata": {},
   "source": [
    "# Data Wrangling in Python\n",
    "\n",
    "> CIT Club event blog & Notebook. The aim of this blog/notebook was to introduce CIT Club members in data wrangling. \n",
    "\n",
    "- author: Victor Omondi\n",
    "- toc: true\n",
    "- comments: true\n",
    "- badges: true\n",
    "- image: images/event_banner.png\n",
    "- categories: [data-wrangling, python, cit-club]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd97d9-3e99-42d0-aff0-f2a55b9282f2",
   "metadata": {},
   "source": [
    "![Wikipedia Definition](https://github.com/VictorOmondi1997/data_wrangling_cit/blob/master/img/wikipedia_def.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41b7b0-d024-47f9-97aa-ac2aafaea54e",
   "metadata": {},
   "source": [
    "# Introductions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc462ac-5623-47b8-9f18-249123a29661",
   "metadata": {},
   "source": [
    "<p><img style=\"float: left;margin:5px 20px 5px 1px;width:500px\" src=\"https://github.com/VictorOmondi1997/data_wrangling_cit/blob/master/img/event_banner.png?raw=true\"></p>\n",
    "\n",
    "Data wrangling is the process of gathering, selecting, and transforming data to answer an analytical question. Also known as data cleaning or “munging”, legend has it that this wrangling costs analytics professionals as much as 80% of their time, leaving only 20% for exploration and modeling.\n",
    "\n",
    "Hello and welcome to **Data Wrangling in Python**. This is a notebook/presentatation/blog used in *Data Science CIT club event*, it depends on how you've accessed it. Depending on how you got this notebook, this is how to work around with it to access the data sets and the entire project.\n",
    "- **Github**\n",
    "  - clone the entire project, instructions are on the [`README.md`](https://github.com/VictorOmondi1997/data_wrangling_cit/blob/master/README.md) file\n",
    "- **Blog**\n",
    "  - click on any of the banners shown at the top of the project\n",
    "    - [![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/VictorOmondi1997/blog/blob/master/_notebooks/2021-11-06-data_wrangling_cit.ipynb)\n",
    "    - [![Binder](https://binder.pangeo.io/badge_logo.svg)](https://mybinder.org/v2/gh/VictorOmondi1997/blog/master?filepath=_notebooks%2F2021-11-06-data_wrangling_cit.ipynb)\n",
    "  \n",
    "## Data Sets\n",
    "- [`client status`](https://raw.githubusercontent.com/VictorOmondi1997/data_wrangling_cit/master/data/client_status.csv): Shows the client status and loan status at the end of the month their status remained the same.\n",
    "- [`kenya_subcounties`](https://raw.githubusercontent.com/VictorOmondi1997/data_wrangling_cit/master/data/kenya_subcounty.csv): shows the county name and sub counties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f56d1-08cd-4f92-8f6c-4a7895d43e52",
   "metadata": {},
   "source": [
    "# 1. Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b8ce2e-1dfc-4725-81cb-becb56c85d18",
   "metadata": {},
   "source": [
    "Before starting data wrangling, we need to first install the necessary libraries needed. \n",
    "- Pandas: Pandas is the popular library used for data analysis and data transformation\n",
    "- numpy: Numpy is a popular library for scientific computing\n",
    "\n",
    "We must import these libraries first, as a convention during importing pandas is aliased to `pd` and numpy as `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b2c78-9dc0-464c-9410-f7287e5a1aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da2fcdeb-f075-49a4-b943-5b3ae00789ae",
   "metadata": {},
   "source": [
    "For the purpose of viewing, some datasets might be having very long or very many columns, therefore we need to make sure pandas will be able to show all columns\n",
    "\n",
    "> Note: Pandas usually truncates columns if they are many"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450bbfb5-8c92-43c4-a591-decec307dab7",
   "metadata": {},
   "source": [
    "![outline](https://github.com/VictorOmondi1997/data_wrangling_cit/blob/master/img/outline.gif?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f171b2-60d5-4437-9a48-24b3ae2ddad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd51e075-9372-48ad-8f1b-afb8559a7d5d",
   "metadata": {},
   "source": [
    "# 2. Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b171e35-507f-4ead-ac8d-10ee3cea1c3d",
   "metadata": {},
   "source": [
    "![Reading Data](https://github.com/VictorOmondi1997/data_wrangling_cit/blob/master/img/read_csv.gif?raw=true)\n",
    "\n",
    "Data might come in very many formats. But mainly, for many data scientists data, the popular used are CSV files. We will use CSV file for our data. Below is how to read CSV with pandas. In pandas, we use `pd.read_csv` to create pandas dataframes from csv. You pass the csv location as a string/variablestring as the first argument. e.g. `pd.read_csv(\"file.csv\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe334c-a0ff-4f39-8f47-75c9c9e56ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af9eb6a2-aae3-4496-a492-c0d4309e0120",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**Create a dataframe known as `counties`, the csv location is https://raw.githubusercontent.com/VictorOmondi1997/data_wrangling_cit/master/data/kenya_subcounty.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a622b86b-c952-47c2-b215-df2a3906087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dbb025-8bb3-4a8f-9697-b85681dc545c",
   "metadata": {},
   "source": [
    "# 3. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b243838-bcb3-4453-9f05-f4322820fe66",
   "metadata": {},
   "source": [
    "![Data Exploration](https://github.com/VictorOmondi1997/data_wrangling_cit/blob/master/img/explore_data.gif?raw=true)\n",
    "\n",
    "Before doing data wrangling or any data cleaning, it is important as a data scientist/analyst to explore your data. This will help you know how the data looks like, how many rows and columns it has. To check the first few rows we use `df.head(n)` where df is the dataframe name and `n` is the number of rows you want to be returned. The same is for `df.tail` and `df.sample`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e7d9a-a679-47f0-8c79-fd3db41d6b79",
   "metadata": {},
   "source": [
    "## 3.1 First few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea66bd7-8e04-4d84-92fc-f91e50c7ea8a",
   "metadata": {},
   "source": [
    "By Default, without passing any argument in `head()`, it will return the first `5` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf7d83-14c3-480b-8cf7-b8df1f6c1601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f739d939-d00d-45c3-abdc-7e84d2385709",
   "metadata": {},
   "source": [
    "Passing the number of rows you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59945cd6-d6d5-4c9e-83f6-4194ba88c2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ab0f837-f786-417f-818c-b08e35fe15ae",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe we created (`counties`) return the first 15 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464c4792-83cb-40bf-b1cf-ce144f232047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a114c90-b424-4d00-856e-c8035350b85c",
   "metadata": {},
   "source": [
    "## 3.2 Last few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c5bcd-a962-46c9-b7a9-356fab127120",
   "metadata": {},
   "source": [
    "The `tail` method returns the last rows of a dataframe, by default it returns the 5 last rows, but you can specify the number of last rows that you need to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d55614-fdd3-4352-87c4-9d9d893b585f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2287b559-fc2f-41de-bd6d-17814efd1ddd",
   "metadata": {},
   "source": [
    "> Tip: As you can see the last `4` rows have metadata on when the data was generated. We will hand this situation in the Reshaping data part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a8b68-464a-4c88-bc1a-48754c0040d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74698433-2840-4ce4-a085-c38e106cc102",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe (`counties`) we created return the last 15 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5e0ff6-4afc-4034-ac15-9f4d8b553689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2557e399-a7fb-4b12-90ce-fd4456dcec7a",
   "metadata": {},
   "source": [
    "## 3.3 sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb07e9-bd30-4129-a27e-e1359e9f2e16",
   "metadata": {},
   "source": [
    "`df.sample` mainly is used during sampling techniques, it a random sample of items from an axis of object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f902436-f1d5-430d-bd79-75fbf6672ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df5aaae7-b15e-431a-bf11-c37326714ab2",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe (`counties`) we created return a sample of `10` rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0282cb0-b9b1-4e6d-9bb3-cc7062e269c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4efd07f-65a0-4145-87fc-14162b656752",
   "metadata": {},
   "source": [
    "## 3.4. Number of Rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a7554-0c48-4b0b-86f5-4e9a52179ff2",
   "metadata": {},
   "source": [
    "In pandas, there are various ways to know how many columns (_variables_) and rows (_observations_) a dataframe has.\n",
    "1. `len(df)` - returns number of rows\n",
    "2. `df.shape` - returns number of rows and columns as a tuple\n",
    "3. `df.info()` - returns data frame info, non null values, columns and data columns and the data type of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758c21d-cf46-4d31-b0cf-2f95bd1569e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a366bbf-2236-4d20-9e59-466017800180",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe (`counties`) we created how many rows and columns does it have?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c5b0fd-b885-48f5-b336-5ff070f862a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ccd4d-fe07-4881-abe0-6244e9762d10",
   "metadata": {},
   "source": [
    "## 3.5 Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda04978-1655-41b7-ada2-14882827f074",
   "metadata": {},
   "source": [
    "`df.info` prints a summary of the data frame, ie, number of rows, columns, data column and their non-null values and the dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8bd968-770a-4a27-a82d-738e42e2e74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "146744d7-1f34-415b-9d25-48c174a86c59",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe (`counties`) we created how many missing values are there in the `name` columns?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9daf54-287c-4101-a3ac-97d48cffe8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce3159-afd6-4a98-84d5-e90e32902873",
   "metadata": {},
   "source": [
    "## 3.6. Describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91ba32-1bea-4b63-84d6-6a9a60b29a92",
   "metadata": {},
   "source": [
    "We use `df.describe()` to get summary statistics, by default it returns the summary statistics of the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c86275-4430-432d-9147-c6d93b1b5132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e4b30bc-c864-40ac-b006-2edc8620434c",
   "metadata": {},
   "source": [
    "To show all summary statistics including those for objects (strings) you can pass `include=\"all\"` to the `df.describe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf96e10-26a2-49f7-8143-c4a1779cfea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4a7a232-83d5-4261-86b6-8e5201627847",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe (`counties`) we created how many unique sub counties are there in Kenya?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a5a4a54-a87e-4534-9b17-ce695742d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf903bc2-9e0f-43c6-b54b-8be1a5cf00bf",
   "metadata": {},
   "source": [
    "# 4. Reshaping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e0120-73af-4be1-8f00-248a5f2ce9f1",
   "metadata": {},
   "source": [
    "![Reshaping Data](https://github.com/VictorOmondi1997/data_wrangling_cit/blob/master/img/reshape_data.gif?raw=true)\n",
    "\n",
    "From the tail that we looked above, we saw that the last 4 rows have the metadata on the generation of the data. Those metadata are not very important in our analysis. We will first remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82793fbe-7021-457e-8b56-7eaf6b5c44c9",
   "metadata": {},
   "source": [
    "## 4.1. Droping Irrelevant Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd178c2-8a8f-435b-9eab-32b87b8fc046",
   "metadata": {},
   "source": [
    "Let's check some of the irrelevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644104d-0647-4d86-96bb-4a6747fe3c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33354842-5c8b-4f9e-8674-670458f3cd38",
   "metadata": {},
   "source": [
    "we can drop these 4 last columns by using `df.drop` and assigning the `index` argument to a list of indeces we want to drop.\n",
    "\n",
    "> Important: If you want to drop columns, use `df.drop(columns=cols)` were cols is a list of column names you want to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30329b3d-53d6-4291-b4ab-6978298ac75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c30c387-22e5-4808-9dda-3a3ce86c3c9a",
   "metadata": {},
   "source": [
    "> Note: We can also drop inplace, no need of assigning it to a variable. This can be done by specifying the `inplace` argument to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a3c322-91da-4b30-ac2d-269f39f703fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "461afbb5-c5ea-4c8a-8b92-cf3cb7234566",
   "metadata": {},
   "source": [
    "## 4.2. Set Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d123864-d11c-41e3-be50-9893de2b6977",
   "metadata": {},
   "source": [
    "For our data frame, `Client ID` column uniquely identifies rows, for our analysis, we won't be doing analysis on this column, we can set `Client ID` to  be the index of our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5c815-3395-489f-88d6-688908e8e380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b72b0f7-85ce-4d5d-a4ce-09b1f882e181",
   "metadata": {},
   "source": [
    "## 4.3. Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91cef9a-c0ff-46b8-a654-34a2622f4286",
   "metadata": {},
   "source": [
    "Sorting is arranging values/index in data either in ascending or descending order. To sort index we use `df.sort_index`, to sort values in columns we use `df.sort_values(cols)` where `cols` is column name or list of column names we want to sort their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f79257-9185-46c0-854a-b04ee992ff3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8571bcf1-4075-4fdc-9406-eacdc4f4ec28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33259998-9e66-4e5c-a1d5-20f22c0f21f3",
   "metadata": {},
   "source": [
    "By defauld the sorting are in ascending order, we can also sort in descending order. To do this, we use `ascending=False` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cea464-4a76-48e7-896e-5657c7c4c1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92900f58-a251-4da1-89e6-adf822c11d3f",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe (`counties`) we created sort the data frame as follows**\n",
    "1. **`name`: descending**\n",
    "2. **`subCounty`: ascending**\n",
    "\n",
    "> Tip: you can use `ascending=[False, True]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f71ce2c0-3d5d-4557-acf4-b3ab67439d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4df8b9-58e4-48bf-9dee-7f7ec9071866",
   "metadata": {},
   "source": [
    "## 4.3. Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b64b2-19e7-4598-929c-025a1ed7db27",
   "metadata": {},
   "source": [
    "Duplicates are rows that are identical to each other, ie, they have the same values. to check for duplicates we use `df.duplicated` this will return a **boolean series** we can use the boolean series to filter out the repeting values and we can use `df.drop_duplicates` to remove any duplicates in the data frame.\n",
    "\n",
    "> Important: the first occurence won't be removed by default.\n",
    "\n",
    "to check for duplicates, we will first reset the index, this will make `Client ID` to be a column as it was before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15207be-a5a5-4c0d-ab9f-19d999d44a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a946f-8ffe-42be-be10-bcbff27a4132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c914093-1a83-460b-bac2-69b74008d56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d16094b-77c3-448f-a120-68bdbf56e602",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe (`counties`), are there any duplicates in that dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aed4076-8af5-4507-aa88-4a190a62d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed03a1-93ab-49a4-9dc5-296e6466fe66",
   "metadata": {},
   "source": [
    "## 4.4. Drop Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5965f6ae-a85d-45be-ba7d-7930677e0c9f",
   "metadata": {},
   "source": [
    "`df.drop_duplicates` removes duplicates keeping first occurence by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d631a-e1d6-459d-bdbe-8c51380a5e94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac52728-0608-4de0-b6a1-475d85911635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91146f34-c835-4234-aba4-ae5f732a2675",
   "metadata": {},
   "source": [
    "## 4.5. Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ad26f-7f48-4ec5-8f5c-ee086868a4d7",
   "metadata": {},
   "source": [
    "Majorly involed during data cleaning. Missing values are values that are missing, alaaa!. In this session we won't go deeper on how to handle missing values. In python, to check for missing values we use `df.isnull()` or `df.isna`, to remove missing values we use `df.dropna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8c437-e4af-495a-bd38-c7ceab7c3328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "159d8729-e530-4d19-886b-fdf1685ff324",
   "metadata": {},
   "source": [
    "That returns a dataframe with boolean showing if a value is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e6312-9c0e-46a6-93bc-9b29b8dda560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af1ce6ae-deff-41c1-8019-0094abf0a3d3",
   "metadata": {},
   "source": [
    "`df.isnull().sum()` is the most widely used way of cheking the number of missing values per column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a703bdb1-386e-402a-9ea6-b54675fed7c7",
   "metadata": {},
   "source": [
    "# 5. Advanced Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ee7d6-a7e1-4304-b2f9-1edf86a028ac",
   "metadata": {},
   "source": [
    "![Advanced Data Wrangling](https://github.com/VictorOmondi1997/data_wrangling_cit/blob/master/img/advanced.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3a713-4f07-457f-8d15-475b82e735ad",
   "metadata": {},
   "source": [
    "## 5.1. Value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640ac55-2a48-4411-a1f1-a129e19f3cfe",
   "metadata": {},
   "source": [
    "As a data scientist it is good to check the counts of unique values, these is mainly used to check for imbalance at later states. To check for the number of unique values, we use `df[col].value_counts()` where `col` is the column name.\n",
    "\n",
    "> Note: `df[col]` is selecting a column returning a series, where `col` is the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ea166-87e3-421b-b5d1-8a5678715605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e99deb2-0333-4663-8ba9-952cb7a8cbaf",
   "metadata": {},
   "source": [
    "By default `.value_counts` drops values which are missing values, we can include the counts of missing values by setting `dropna=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7173f0b6-6151-4efa-ae74-bcd6f8c2f20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b244c91-8ef9-4463-b61d-5102ed072c87",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe (`counties`) Show the value counts of the `name` variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d4c487-e5dc-4717-a465-03d6217be6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f0931-9345-4561-aa73-ee90e1a808b3",
   "metadata": {},
   "source": [
    "## 5.2. Data Filteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b28ab-7789-4b7d-a84b-27938f29df35",
   "metadata": {},
   "source": [
    "In pandas \n",
    "- we can use comparison operators to filter data meeting a certain condition, \n",
    "- to filter columns we can use `df[[col1....coln]`, \n",
    "- to filter rows based on their index we can use \n",
    "  - `iloc[i]` or `loc[strn]` for integer based or label based indexing respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f9436-4b03-430b-ab69-9e52f89c5999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af108ea4-d87f-491e-bf6a-cca9a1b7c638",
   "metadata": {},
   "source": [
    "We can use comparison operators for filtering values that meet a certain condition.\n",
    "- `>` - Greater than\n",
    "- `<` - Less than\n",
    "- `>=` - Greater or equal to\n",
    "- `<=` - Less than or equal to\n",
    "- `==` equal to\n",
    "- `!=` not equal to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba69066-56b1-4abf-aedc-545ed2ec6b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fceb2eaf-0ee4-4b6b-be57-2a9292749ae0",
   "metadata": {},
   "source": [
    "`df[col]>value` returns a boolean series, we can use the boolean series to filter out values in dataframe not meeting that condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544b83c-3dbd-4952-8aef-d91c43e1e34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab200861-7e0a-425f-b3fe-359b9c4a74e0",
   "metadata": {},
   "source": [
    "### 5.2.1. Multiple conditions filterring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6e8b4c-7daa-41b2-9b69-f5650fa05b35",
   "metadata": {},
   "source": [
    "We can use logical conditions to support two or more expressions. In pandas we we can use the following operators:\n",
    "\n",
    "- `&`: for logical **and**\n",
    "- `|`: for logical **or**\n",
    "- `~`: for logical **not**\n",
    "\n",
    "> Important: Paranthesis are very important. enclose expressions in a paranthesis `(.....)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a9654d-79c6-465c-a18f-15efafe3ca85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f52a259a-9507-487b-9b49-4553538014fc",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe (`counties`) Filter the data to select dataset where `name` is equal to `'Nakuru'` & `subCounty` is not equal to `'Naivasha'`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd64bbd0-c80d-4459-a9a1-e323bd5d7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40760d6-7c96-4420-b73f-1ef527dd9c58",
   "metadata": {},
   "source": [
    "## 5.3. Grouping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf77a83-4084-408f-9c92-eefea19eb6af",
   "metadata": {},
   "source": [
    "Grouping data is a critical step in data wrangling. in pandas we can group DataFrame using a mapper or by a Series of columns.\n",
    "\n",
    "A groupby operation involves some combination of splitting the object, applying a function, and combining the results. This can be used to group large amounts of data and compute operations on these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc0b07-77cb-47bc-8963-5e03bc3aaa49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f027222-677b-42a9-abca-10142d436ac7",
   "metadata": {},
   "source": [
    "The groupby returns an object, we can use the object to perform actions in the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af3532-3b31-4e2e-8c32-ea9edc7a99d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3122fff-71fe-4734-b84d-28591660a1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162920f6-6418-428d-a3c4-599a808c35dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dc607e0-7e98-4816-bf7e-765bf634dd4f",
   "metadata": {},
   "source": [
    "To check for the size of each group, we can use `size()` method of a groupby object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04334517-9799-4020-8bcf-16302af17056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf2711c-e410-4258-afec-64904805682a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1124b28a-68d6-45e1-9cfa-39a0444b123c",
   "metadata": {},
   "source": [
    "Pivot table (derived from excel) is an advanced pandas grouping method.\n",
    "Here you can decide on the index, columns, values and the aggregate functions. The levels in the pivot table will be stored in MultiIndex objects (hierarchical indexes) on the index and columns of the result DataFrame.\n",
    "\n",
    "the aggfunc by default is mean. You can pass string aggregates eg `'mean'`, `'sum'` ect or aggregate functions such as `np.mean`, `np.sum` etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57d834-516f-4163-be14-3178c55878f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e2f2d26-5f80-4c4d-a900-d17704e9e795",
   "metadata": {},
   "source": [
    "setting `margins=True` will result to row aggregate and column column aggregate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928128e8-2e60-4878-9852-820bc7e32494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36ba5b86-3221-4a28-8bfb-5c3c2a8b4bff",
   "metadata": {},
   "source": [
    "## 5.4. Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46052446-83bd-4c02-af89-1be95658913e",
   "metadata": {},
   "source": [
    "the are varies ways of combining data sets\n",
    "- append - add rows to the end of the caller.\n",
    "- concatenate\n",
    "- merge \n",
    "  - inner join\n",
    "  - left join\n",
    "  - right join\n",
    "  \n",
    "Type of merge to be performed.\n",
    "- left: use only keys from left frame, similar to a SQL left outer join; preserve key order.\n",
    "- right: use only keys from right frame, similar to a SQL right outer join; preserve key order.\n",
    "- outer: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.\n",
    "- inner: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys.\n",
    "- cross: creates the cartesian product from both frames, preserves the order of the left keys.\n",
    "\n",
    "We use `df.merge`/`pd.merge` to import columns from other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84797a40-4bd6-4710-ac1a-5af1f31da221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84bd9a22-25dc-410a-bf79-1158d8b9be27",
   "metadata": {},
   "source": [
    "We can merge `status` and `counties` using `Office` and `subCounty` (this is because that is the key present in both columns. Since we have diffent column names in both data frames, we have to use `left_on` and `right_on` to specify the columns.\n",
    "\n",
    "if the columns are the same on both columns, we can use `on` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bdfd9-5d3e-468a-b53a-4f3e7a483ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d0793f0-bf07-4c4e-a25f-5876137b31a3",
   "metadata": {},
   "source": [
    "Another method is using the `pd.merge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb752a-aa51-41a1-9ec6-6c3a610bc71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b70c18ef-82d6-4169-b30f-c93dc5c8c909",
   "metadata": {},
   "source": [
    "### **EXERCISE**\n",
    "**For the dataframe (`counties`) do a full outer join with `status` dataframe, how many rows does it have?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63d325cf-9227-439a-b2e3-8e6a14ee058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3650c-3f7e-41a1-86ae-af337a515f14",
   "metadata": {},
   "source": [
    "# 7. Exporting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff455c-0a4f-4883-9ac7-0c7b5d37f1c5",
   "metadata": {},
   "source": [
    "After finishing data wrangling, it is good to export the data to the right file format for further uses. Let us do some final tweaks and export the final dataset as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc16b0c-5ec1-4b54-926c-e9f7eab511c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47833585-78f2-4925-91c8-ea2af7a1285a",
   "metadata": {},
   "source": [
    "# 6. More Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0c013-e90e-4201-8ec0-7646c333d80e",
   "metadata": {},
   "source": [
    "1. https://pandas.pydata.org/pandas-docs/stable/index.html\n",
    "2. https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9bb92-43a4-4035-8ab1-7c2e39419121",
   "metadata": {},
   "source": [
    "# About the Speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72189b6-cbcc-43df-926f-14984c8d334a",
   "metadata": {},
   "source": [
    "![Victor](https://github.com/VictorOmondi1997/data_wrangling_cit/blob/master/img/vick.gif?raw=true)\n",
    "\n",
    "<p align=\"center\"><a href=\"https://github.com/VictorOmondi1997\"><img src=\"https://img.shields.io/github/followers/VictorOmondi1997.svg?label=GitHub&style=social\" alt=\"GitHub\"></a>\n",
    "\t<a href=\"https://twitter.com/VictorOmondi197\"><img src=\"https://img.shields.io/twitter/follow/VictorOmondi197?label=Twitter&style=social\" alt=\"Twitter\"></a>\n",
    "\t<a href=\"https://www.linkedin.com/in/VictorOmondi1997\"><img src=\"https://img.shields.io/badge/LinkedIn--_.svg?style=social&logo=linkedin\" alt=\"LinkedIn\"></a>\n",
    "\t<a href=\"https://github.com/sponsors/VictorOmondi1997\"><img src=\"https://img.shields.io/badge/Sponsors--_.svg?style=social&logo=github&logoColor=EA4AAA\" alt=\"Sponsors\"></a></p>\n",
    "   \n",
    "Thank you for attending todays session. \n",
    "\n",
    "- For more Consultation you can schedule a meeting at [Calendly](https://calendly.com/VictorOmondi1997)\n",
    "- Send Email: <a href=\"mailto:info.victoromondi@gmail.com\">info.victoromondi@gmail.com</a> or <a href=\"mailto:victor.omondi@inukaafrica.com\">victor.omondi@inukaafrica.com</a>\n",
    "- Call/Text/Whatsapp: <a href=\"tel:254797817059\">+254797817059</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47f047-6518-4cac-a4bb-f16d28e46f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
